{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUOXHTYrWzjw"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries in Colab\n",
        "!pip install lightgbm catboost xgboost optuna\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.impute import SimpleImputer\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from google.colab import files\n",
        "import optuna\n",
        "\n",
        "# Load data from Google Drive links\n",
        "train_url = \"https://drive.google.com/file/d/1c3XaTRGyN9Cy2Ffnb26DlfZowi3zxE2T/view?usp=sharing\"\n",
        "test_url = \"https://drive.google.com/file/d/1-fP60UWTyCb45r7vBrPOkU_LrE0TTn-Q/view?usp=sharing\"\n",
        "train_path = 'https://drive.google.com/uc?export=download&id=' + train_url.split('/')[-2]\n",
        "test_path = 'https://drive.google.com/uc?export=download&id=' + test_url.split('/')[-2]\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n",
        "\n",
        "# Separate target and features\n",
        "y_train = np.log1p(train_data.pop(\"SalePrice\"))\n",
        "X_train = train_data.drop(\"Id\", axis=1)\n",
        "id_column = test_data.pop('Id')\n",
        "\n",
        "# Feature Engineering\n",
        "class FeatureEngineering:\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Aggregate Features\n",
        "        X['TotalSF'] = X['1stFlrSF'] + X['2ndFlrSF'] + X['TotalBsmtSF']\n",
        "        X['TotalBathrooms'] = X['FullBath'] + (0.5 * X['HalfBath']) + X['BsmtFullBath'] + (0.5 * X['BsmtHalfBath'])\n",
        "        X['HouseAge'] = X['YrSold'] - X['YearBuilt']\n",
        "\n",
        "        # Interaction Features\n",
        "        X['GrLivArea_OverallQual'] = X['GrLivArea'] * X['OverallQual']\n",
        "        X['GrLivArea_log'] = np.log1p(X['GrLivArea'])\n",
        "\n",
        "        return X\n",
        "\n",
        "# Define pipelines for numeric and categorical features\n",
        "numeric_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
        "])\n",
        "\n",
        "categoric_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_pipe, make_column_selector(dtype_include=np.number)),\n",
        "    ('cat', categoric_pipe, make_column_selector(dtype_include=object))\n",
        "])\n",
        "\n",
        "# Define base models with recommended settings\n",
        "lgb_model = LGBMRegressor(\n",
        "    objective='regression',\n",
        "    random_state=123,\n",
        "    colsample_bytree=0.75,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=4,\n",
        "    n_estimators=1200,\n",
        "    subsample=0.85\n",
        ")\n",
        "\n",
        "cat_model = CatBoostRegressor(\n",
        "    iterations=1200,\n",
        "    learning_rate=0.02,\n",
        "    depth=7,\n",
        "    random_seed=123,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "xgb_model = XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    random_state=123,\n",
        "    colsample_bytree=0.75,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=4,\n",
        "    n_estimators=1200,\n",
        "    subsample=0.85\n",
        ")\n",
        "\n",
        "# Define stacking ensemble with tuned Ridge meta-learner\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=[\n",
        "        ('lgb', lgb_model),\n",
        "        ('cat', cat_model),\n",
        "        ('xgb', xgb_model)\n",
        "    ],\n",
        "    final_estimator=Ridge(alpha=0.5)\n",
        ")\n",
        "\n",
        "# Full pipeline with feature engineering, preprocessing, and stacking model\n",
        "pipeline = Pipeline([\n",
        "    ('feature_eng', FeatureEngineering()),\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', stacking_model)\n",
        "])\n",
        "\n",
        "# Fit pipeline on training data\n",
        "print(\"Fitting model with stacking ensemble of LightGBM, CatBoost, and XGBoost...\")\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on training set\n",
        "train_pred = pipeline.predict(X_train)\n",
        "train_rmse = mean_squared_error(y_train, train_pred, squared=False)\n",
        "print(\"Training RMSE (log scale):\", train_rmse)\n",
        "\n",
        "# Predictions on test data and prepare submission\n",
        "test_pred = np.expm1(pipeline.predict(test_data))\n",
        "submission = pd.DataFrame({'Id': id_column, 'SalePrice': test_pred})\n",
        "\n",
        "# Save submission file\n",
        "submission_file = 'submission_stacking_ensemble.csv'\n",
        "submission.to_csv(submission_file, index=False)\n",
        "files.download(submission_file)\n",
        "\n",
        "print(f\"Submission file saved as {submission_file} and downloaded.\")\n"
      ]
    }
  ]
}